{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d245b-1d0b-41f6-861e-81e6a914eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import textstat\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import math\n",
    "from IPython.display import FileLink\n",
    "import concurrent.futures\n",
    "import time\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fae892-6549-4013-98e4-a03ef13a675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prompts \n",
    "from jh_pfx_prompts import example, icd10_example, baseline_zeroshot_prompt, single_fewshot_prompt, single_fewshot_icd10_labeling_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b806945-d1be-4532-87c6-491eee710378",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c3358-9030-4889-ab30-51f18c8af1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "CLIENT = OpenAI(api_key = OPENAI_API_KEY)\n",
    "OPENAI_MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc40c2-3c5a-441e-8ba1-90634fdf1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading levels\n",
    "PROFESSIONAL = \"Professional\"\n",
    "COLLEGE_GRADUATE = \"College Graduate\"\n",
    "COLLEGE = \"College\"\n",
    "TENTH_TO_TWELTH_GRADE = \"10th to 12th grade\"\n",
    "EIGTH_TO_NINTH_GRADE = \"8th to 9th grade\"\n",
    "SEVENTH_GRADE = \"7th grade\"\n",
    "SIXTH_GRADE = \"6th grade\"\n",
    "FIFTH_GRADE = \"5th grade\"\n",
    "N_A = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afdcf14-a31e-4e45-a273-c5c3bcdec6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch_reading_ease\n",
    "def map_reading_level(flesch_reading_ease):\n",
    "    if flesch_reading_ease < 10:\n",
    "        return PROFESSIONAL\n",
    "    elif 10.0 <= flesch_reading_ease < 30.0:\n",
    "        return COLLEGE_GRADUATE\n",
    "    elif 30.0 <= flesch_reading_ease < 50.0:\n",
    "        return COLLEGE\n",
    "    elif 50.0 <= flesch_reading_ease < 60.0:\n",
    "        return TENTH_TO_TWELTH_GRADE\n",
    "    elif 60.0 <= flesch_reading_ease < 70.0:\n",
    "        return EIGTH_TO_NINTH_GRADE\n",
    "    elif 70.0 <= flesch_reading_ease < 80.0:\n",
    "        return SEVENTH_GRADE\n",
    "    elif 80.0 <= flesch_reading_ease < 90.0:\n",
    "        return SIXTH_GRADE\n",
    "    elif 90.0 <= flesch_reading_ease < 100.0:\n",
    "        return FIFTH_GRADE \n",
    "    else:\n",
    "        return N_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1316eb-d199-4bfb-be52-6434be136705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading ease variables\n",
    "fifth_grade = 95\n",
    "sixth_grade = 85\n",
    "seventh_grade = 75\n",
    "eigth_and_ninth_grade = 65\n",
    "tenth_to_twelfth_grade = 55\n",
    "college = 40\n",
    "college_graduate = 20\n",
    "professional = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357c2aa-58ca-48b5-bec6-6d6b3308ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_difference(diff, threshold):\n",
    "    \"\"\"Adjust the readability difference based on the threshold.\"\"\"\n",
    "    if diff > threshold:\n",
    "        return diff - threshold\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a10b5-4087-4563-b870-c96ed41b721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fewshot examples\n",
    "df_fewshot = pd.read_csv('pfx_fewshot_examples_college.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f3b8a-c6d1-4c92-9dc7-65575baae950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evaluation data \n",
    "df_eval = pd.read_csv('missingmf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c40053-bb02-4ecc-93f3-2b569025aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_eval.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59fc90-4ca0-45ab-8388-71ade7bc6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(openai_response):\n",
    "    if openai_response:  # Ensure the response is not None\n",
    "        # Directly search for JSON within the string response\n",
    "        json_match = re.search(r'```.*?(\\{.*?\\}).*?```', openai_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)  # Extract JSON-like content\n",
    "            try:\n",
    "                # Convert extracted string to a JSON object\n",
    "                json_object = json.loads(json_str.replace('\\n', ''))\n",
    "                return json_object\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Handle JSON decoding errors\n",
    "                print(\"JSON decoding failed: \", e)\n",
    "                return {}\n",
    "        else:\n",
    "            print(\"No JSON object found in the response.\")\n",
    "            return {}\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a134d-1dfc-4034-928c-d2829190af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_icd10s(pfx_output):\n",
    "    \"\"\"\n",
    "    Takes a single PFx response (string or JSON) and returns\n",
    "    a labeled ICD-10 result as a Python dictionary (or object).\n",
    "    \"\"\"\n",
    "\n",
    "    # Build up the few-shot examples for ICD-10 labeling\n",
    "    pfx_icd10_fewshot_examples = \"\"\n",
    "    for i, row in df_fewshot.iterrows():\n",
    "        pfx_icd10_fewshot_examples += icd10_example.format(**row)\n",
    "\n",
    "    # Generate the prompt for ICD-10 labeling\n",
    "    # (Adjust the '{PFx}' if pfx_output is a dictionary with a specific key you need)\n",
    "    prompt = single_fewshot_icd10_labeling_prompt.format(\n",
    "        examples=pfx_icd10_fewshot_examples,\n",
    "        PFx=pfx_output  # or PFx=pfx_output['key'] if needed\n",
    "    )\n",
    "\n",
    "    # Call the model to get ICD-10 codes\n",
    "    pfx_icd10_response = CLIENT.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an ICD10 medical coder for incidental findings. Always respond with a valid JSON object containing the ICD-10 code and its explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    # Extract the JSON structure (or dictionary) from the LLM response\n",
    "    labeled_result = extract_json(pfx_icd10_response.choices[0].message.content)  # Accessing the message content\n",
    "\n",
    "    return labeled_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bef33-ec7a-4260-b66a-d9736c08b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the results DataFrame\n",
    "results_df = pd.DataFrame(columns=[\"finding\", \"ICD10_code\", \"PFx\", \"PFx_ICD10_code\"])\n",
    "\n",
    "# Generate few-shot examples\n",
    "pfx_fewshot_examples = \"\"\n",
    "for i, row in df_fewshot.iterrows():\n",
    "    pfx_fewshot_examples += example.format(**row)\n",
    "\n",
    "# Generate PFx for each row in df_eval with 5 runs\n",
    "for i, row in df_eval.iterrows():\n",
    "    for run in range(5):  # Perform 5 runs\n",
    "        # Format the prompt\n",
    "        prompt = single_fewshot_prompt.format(\n",
    "            Examples=pfx_fewshot_examples,\n",
    "            Incidental_Finding=row[\"Incidental_Finding\"],\n",
    "            Reading_Level=SIXTH_GRADE\n",
    "        )\n",
    "        \n",
    "        # Generate response from the client\n",
    "        pfx_response = CLIENT.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical doctor rephrasing and explaining medical terminology to a patient in an understandable manner.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "        )\n",
    "        \n",
    "        # Extract JSON from the response\n",
    "        extracted_response = extract_json(pfx_response.choices[0].message.content)\n",
    "        \n",
    "        # Create a new DataFrame for the current row\n",
    "        new_row = pd.DataFrame({\n",
    "            \"finding\": [row[\"Incidental_Finding\"]],\n",
    "            \"ICD10_code\": [row.get(\"ICD-10 Code\", None)],  # Handle missing 'ICD10_code'\n",
    "            \"PFx\": [extracted_response[\"PFx\"]],  # Extracted explanation\n",
    "            \"PFx_ICD10_code\": [extracted_response.get(\"PFx_ICD10_code\", None)]  # Optional field\n",
    "        })\n",
    "        \n",
    "        # Concatenate the new row to the results DataFrame\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520753e-f384-4b5c-9f63-c325d58a74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import concurrent.futures\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=\"openai_api.log\", level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Initialize OpenAI Client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Initialize the results DataFrame\n",
    "results_df = pd.DataFrame(columns=[\"finding\", \"ICD10_code\", \"PFx\", \"PFx_ICD10_code\"])\n",
    "\n",
    "# Generate few-shot examples\n",
    "pfx_fewshot_examples = \"\\n\".join(example.format(**row.to_dict()) for _, row in df_fewshot.iterrows())\n",
    "\n",
    "# Function to generate a request\n",
    "def create_task(row_idx, run):\n",
    "    prompt = single_fewshot_prompt.format(\n",
    "        Examples=pfx_fewshot_examples,\n",
    "        Incidental_Finding=df_eval.iloc[row_idx][\"Incidental_Finding\"],\n",
    "        Reading_Level=SIXTH_GRADE\n",
    "    )\n",
    "    return {\n",
    "        \"custom_id\": f\"task-{row_idx}-run-{run}\",\n",
    "        \"model\": OPENAI_MODEL,\n",
    "        \"temperature\": 0.0,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a medical professional rephrasing and explaining medical terminology to a patient in an understandable manner.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"row_idx\": row_idx\n",
    "    }\n",
    "\n",
    "# Prepare batch requests (5 per row)\n",
    "batch_requests = [create_task(i, run) for i in range(len(df_eval)) for run in range(5)]\n",
    "\n",
    "# Function to call OpenAI API with retry logic\n",
    "def call_openai_api(task):\n",
    "    \"\"\"Calls OpenAI API and ensures a valid response with retries.\"\"\"\n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=task[\"model\"],\n",
    "                messages=task[\"messages\"],\n",
    "                temperature=task[\"temperature\"]\n",
    "            )\n",
    "            return task[\"custom_id\"], response, task[\"row_idx\"]\n",
    "        except openai.OpenAIError as e:\n",
    "            wait_time = (attempt + 1) * 2\n",
    "            logging.warning(f\"API error for {task['custom_id']}: {e}. Retrying in {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "    logging.error(f\"Failed after {max_retries} attempts: {task['custom_id']}\")\n",
    "    return task[\"custom_id\"], None, task[\"row_idx\"]\n",
    "\n",
    "# Run API calls in parallel\n",
    "results = []\n",
    "max_workers = 13\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_task = {executor.submit(call_openai_api, task): task for task in batch_requests}\n",
    "\n",
    "    for future in concurrent.futures.as_completed(future_to_task):\n",
    "        task = future_to_task[future]\n",
    "        try:\n",
    "            custom_id, response, row_idx = future.result()\n",
    "            if response:\n",
    "                results.append({\"custom_id\": custom_id, \"row_idx\": row_idx, \"response\": response})\n",
    "            else:\n",
    "                logging.warning(f\"Missing response for {custom_id}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error with {task['custom_id']}: {e}\")\n",
    "\n",
    "# Strict check: Ensure 5 responses per row\n",
    "responses_per_row = defaultdict(list)\n",
    "for item in results:\n",
    "    responses_per_row[item[\"row_idx\"]].append(item)\n",
    "\n",
    "# Identify missing responses\n",
    "missing_tasks = []\n",
    "for row_idx in range(len(df_eval)):\n",
    "    count = len(responses_per_row[row_idx])\n",
    "    if count < 5:\n",
    "        missing_runs = list(range(count, 5))  # Find missing runs\n",
    "        logging.warning(f\"Row {row_idx} only received {count}/5 responses. Retrying {len(missing_runs)} requests.\")\n",
    "        for run in missing_runs:\n",
    "            missing_tasks.append(create_task(row_idx, run))\n",
    "\n",
    "# Retry missing responses (if any)\n",
    "if missing_tasks:\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {executor.submit(call_openai_api, task): task for task in missing_tasks}\n",
    "        for future in concurrent.futures.as_completed(future_to_task):\n",
    "            task = future_to_task[future]\n",
    "            try:\n",
    "                custom_id, response, row_idx = future.result()\n",
    "                if response:\n",
    "                    responses_per_row[row_idx].append({\"custom_id\": custom_id, \"row_idx\": row_idx, \"response\": response})\n",
    "                else:\n",
    "                    logging.warning(f\"Missing response for retry {custom_id}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Unexpected error with retry {task['custom_id']}: {e}\")\n",
    "\n",
    "# Final verification: Log any remaining missing responses\n",
    "for row_idx in range(len(df_eval)):\n",
    "    count = len(responses_per_row[row_idx])\n",
    "    if count < 5:\n",
    "        logging.error(f\"FINAL WARNING: Row {row_idx} still missing {5 - count} responses despite retries.\")\n",
    "\n",
    "# Process responses & update DataFrame\n",
    "new_rows = []\n",
    "for row_idx in responses_per_row:\n",
    "    for item in responses_per_row[row_idx]:\n",
    "        task_id = item[\"custom_id\"]\n",
    "        content = item[\"response\"].choices[0].message.content.strip()\n",
    "\n",
    "        if not content:\n",
    "            logging.warning(f\"Empty response for {task_id}\")\n",
    "            extracted_response = {\"PFx\": \"ERROR: No response\", \"PFx_ICD10_code\": \"ERROR\"}\n",
    "        else:\n",
    "            try:\n",
    "                extracted_response = extract_json(content)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"JSON extraction failed for {task_id}: {e}\")\n",
    "                extracted_response = {\"PFx\": \"ERROR: JSON parsing failed\", \"PFx_ICD10_code\": \"ERROR\"}\n",
    "\n",
    "        new_rows.append({\n",
    "            \"finding\": df_eval.iloc[row_idx][\"Incidental_Finding\"],\n",
    "            \"ICD10_code\": df_eval.iloc[row_idx].get(\"ICD-10 Code\", None),\n",
    "            \"PFx\": extracted_response[\"PFx\"],\n",
    "            \"PFx_ICD10_code\": extracted_response.get(\"PFx_ICD10_code\", None)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add869b-c9c7-4224-9317-6df739f6b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355f7c3-d066-4ebc-9cb6-b582b32e05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"mftest55.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b96bb8-5663-4367-8a99-d849fb8d7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f447b1b-13da-41b7-95c8-9e879721c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_df = results_df.iloc[175:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24822236-8ba7-447d-b8ad-2cc1fe4830ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3b6bf-063e-43e1-93e7-4ecb369ea7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list to store the labeled ICD10 responses\n",
    "labeled_icd10_responses_2 = []\n",
    "\n",
    "# Iterate over each response in results and apply label_icd10s functions \n",
    "for response in results_2_df['PFx']:\n",
    "    labeled_icd10_responses_2.append(label_icd10s(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16283d4e-89c7-4b94-9b67-7e5ed030c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_icd10_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621a4f1-b95c-4dd8-b81c-4e3ca006efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labeled_icd10_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdf244-f903-4d5d-abbf-4882ea83de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_icd10_responses += labeled_icd10_responses_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9714e-bae1-47d8-9738-854596f77550",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labeled_icd10_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772a03b-5138-420e-bd1e-b8e4fbdf688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the results\n",
    "agent_icd10_codes = []\n",
    "icd10_matches = []\n",
    "pfx_icd10_matches = []\n",
    "flesch_scores = []\n",
    "\n",
    "agent_icd10_codes.extend([list(x.values())[0] if x else \"\" for x in labeled_icd10_responses])\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    # Compare to the \"ICD10_code\" in your DataFrame (if it exists)\n",
    "    agent_icd10_code = agent_icd10_codes[index]\n",
    "    icd10_match = (row[\"ICD10_code\"] == agent_icd10_code)\n",
    "    icd10_matches.append(icd10_match)\n",
    "\n",
    "    # compare \n",
    "    pfx_icd10_match = (row[\"PFx_ICD10_code\"] == row[\"ICD10_code\"])\n",
    "    pfx_icd10_matches.append(pfx_icd10_match)\n",
    "\n",
    "    # Calculate the Flesch Reading Ease score\n",
    "    flesch_score = textstat.flesch_reading_ease(row['PFx'])\n",
    "    flesch_scores.append(flesch_score)\n",
    "\n",
    "# Add the results to the DataFrame\n",
    "results_df['_0_agent_icd10_codes'] = agent_icd10_codes\n",
    "results_df['_0_icd10_matches'] = icd10_matches\n",
    "results_df['_0_pfx_icd10_matches'] = pfx_icd10_matches\n",
    "results_df['_0_flesch'] = flesch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acf998-5321-44af-b698-f750d316d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_reading_ease = sixth_grade\n",
    "# Calculate threshold for penalty\n",
    "if desired_reading_ease >= 55:\n",
    "    threshold = 10\n",
    "else:\n",
    "    threshold = 20\n",
    "\n",
    "# Create lists to store the results\n",
    "accuracy_icd10_matches_list = []\n",
    "accuracy_pfx_matches_list = []\n",
    "readability_difference_list = []\n",
    "overall_score_list = []\n",
    "log_overall_score_list = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in results_df.iterrows():\n",
    "    # Calculate accuracy score\n",
    "    accuracy_icd10_matches = row[\"_0_icd10_matches\"]\n",
    "    accuracy_pfx_matches = row[\"_0_pfx_icd10_matches\"]\n",
    "    flesch_score = row[\"_0_flesch\"]\n",
    "\n",
    "    # total number of icd10 matches\n",
    "    total_icd10_matches = accuracy_icd10_matches + accuracy_pfx_matches\n",
    "\n",
    "    # Adjust weights for overall score\n",
    "    # Calculate readability score \n",
    "    readability_score = flesch_score\n",
    "    readability_difference = abs(readability_score - desired_reading_ease)\n",
    "\n",
    "    # Compute the overall score\n",
    "    overall_score = total_icd10_matches * 0.8  + 0.2 * (1/(readability_difference + 1))\n",
    "\n",
    "    # Calculate readability score\n",
    "    readability_difference_log = desired_reading_ease - flesch_score\n",
    "    if readability_difference_log <= threshold:  # No penalty if difference is within the threshold\n",
    "        readability_difference_p = 0\n",
    "    else:  # Apply penalty only if readability exceeds the threshold\n",
    "        readability_difference_with_threshold = readability_difference_log - threshold\n",
    "        readability_difference_p = math.log(1 + readability_difference_with_threshold) / math.log(20)\n",
    "\n",
    "    log_overall_score = total_icd10_matches * 0.8 + readability_difference_log * 0.2\n",
    "\n",
    "    # Append results to lists\n",
    "    accuracy_icd10_matches_list.append(float(accuracy_icd10_matches))\n",
    "    accuracy_pfx_matches_list.append(float(accuracy_pfx_matches))\n",
    "    readability_difference_list.append(float(readability_difference))\n",
    "    overall_score_list.append(float(overall_score))\n",
    "    log_overall_score_list.append(float(log_overall_score))\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "grades_data = {\n",
    "    \"accuracy_agent_icd10\": accuracy_icd10_matches_list,\n",
    "    \"accuracy_pfx_icd10\": accuracy_pfx_matches_list,\n",
    "    \"readability_difference\": readability_difference_list,\n",
    "    \"overall_score\": overall_score_list,\n",
    "    \"log_overall_score\": log_overall_score_list,\n",
    "}\n",
    "grades = pd.DataFrame(grades_data)\n",
    "results_df = pd.concat([results_df, grades], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe4c12-7132-4666-aa70-85889261b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54bc3b-9251-4d13-aa35-eb78a9cf0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=\"finding\", ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0907bff-ec0f-43bf-930c-3e94a9a1d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('mf_pfx_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614d53d-ee75-420f-b4bb-027e9bfe5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('mf_pfx_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f0eda-76fc-4ba5-ac81-ae236a4e5794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
